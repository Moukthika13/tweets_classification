{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                            \"\"\"Classifying tweets\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For this particular assignment I have obtained a labelled dataset from Vinaykoal's github page.\n",
    "The data contains tweets of two major categories 'Sports' and 'Politics'.\n",
    "\n",
    "The following code shows two approaches to the tweet classification\n",
    "\n",
    "1. supervised learning approach \n",
    "\n",
    "2. Unsupervised learning approach\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        \"\"\"Supervised learning Approach\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moukthika\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "import numpy\n",
    "from gensim.matutils import hellinger\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sports</td>\n",
       "      <td>99 days to go until the start of #ct13 did you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports</td>\n",
       "      <td>tonight scottish first division match between ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports</td>\n",
       "      <td>10 off the over 10 required captain faulkner t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politics</td>\n",
       "      <td>. gsanetwork raises awareness &amp;amp stands up t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sports</td>\n",
       "      <td>another wonderful start from england new ball ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Politics</td>\n",
       "      <td>#food minister there will now be legal entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sports</td>\n",
       "      <td>precious four to hartley with time running out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Politics</td>\n",
       "      <td>blasts deja vu how many times have we been in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Politics</td>\n",
       "      <td>rt @fa books book of the day why the occasiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sports</td>\n",
       "      <td>#djokovic wants to keep it sweet #ausopen #3pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                              tweet\n",
       "0    Sports  99 days to go until the start of #ct13 did you...\n",
       "1    Sports  tonight scottish first division match between ...\n",
       "2    Sports  10 off the over 10 required captain faulkner t...\n",
       "3  Politics  . gsanetwork raises awareness &amp stands up t...\n",
       "4    Sports  another wonderful start from england new ball ...\n",
       "5  Politics  #food minister there will now be legal entitle...\n",
       "6    Sports  precious four to hartley with time running out...\n",
       "7  Politics  blasts deja vu how many times have we been in ...\n",
       "8  Politics  rt @fa books book of the day why the occasiona...\n",
       "9    Sports  #djokovic wants to keep it sweet #ausopen #3pe..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the data\n",
    "\n",
    "col_names = ['category', 'tweet']\n",
    "df = pd.read_csv('/Users/moukthika/Desktop/wkc/data_twitter.csv', names = col_names, encoding = 'latin1')\n",
    "df.sample(frac=1)\n",
    "df.head(10)\n",
    "\n",
    "#the dataset contains tweets and the corresponding label. The primary classes are 'sports' and 'politics'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the french in mali expelling the islamists was the easy part now what http //t co 2rcfieyscl : Politics\n"
     ]
    }
   ],
   "source": [
    "#playing around with data\n",
    "print( df.tweet[395], \":\", df.category[395])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae5f2b00f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the data to understand the distribution of the tweets among the two classes. \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df.groupby('category').tweet.count().plot.bar(ylim=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"From the above plot, it is clear that there are more sports tweets in the data set than political tweets\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the data before vectorising it.\n",
    "\n",
    "porter = PorterStemmer()\n",
    "def preprocessing(string):\n",
    "    words = nltk.word_tokenize(string) #splitting the sentences into words\n",
    "    words = [w.lower() for w in words] #converting all words to lower case to avoid have separate vectors for words such as \"now\" and \"Now\" i\n",
    "    #words = [word for word in words if word.isalpha()] #removing everything that is not alphabetic to get rid of punctuations.\n",
    "    \n",
    "    \"\"\"it is good to retain the non-alpha numeric characters here because a lot is expressd through hashtags, @ and other symbols\n",
    "    as it is a microbloggig site allowing a user to type only a certain number of words.\"\"\"\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    words = [w for w in words if not w in stop_words] \n",
    "    \n",
    "    stemmed = [porter.stem(word) for word in words] #to reduce the word to it's root/base. Since we are not looking at a deeper meaning of a word here and want to reduce the vocanulary size.\n",
    "    words = stemmed\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6550, 741)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Since we cannot work with text directly for ML algorithms, the text has to be converted to meaninful numbers. \n",
    "One way of doing it is with Bag of Words model.\n",
    "In Bag of Words model one can get rid of the sequential data (which is language) and only focus on the word occurances, \n",
    "Tfidf is one type of Bag of Words model. \n",
    "This is an acronym than stands for “Term Frequency – Inverse Document” Frequency which are the components of the resulting scores assigned to each word.\n",
    "Term Frequency: This summarizes how often a given word appears within a document.\n",
    "Inverse Document Frequency: This downscales words that appear a lot across documents.\"\"\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=10, max_df = 15, norm='l2', encoding='latin-1', ngram_range=(1,3), tokenizer = preprocessing)\n",
    "\n",
    "features = tfidf.fit_transform(df.tweet).toarray() #the tfidf vectors of the questions will serve as features\n",
    "labels = df.category\n",
    "features.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the test and train set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['tweet'], df['category'], random_state = 42, test_size = 0.2)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        \"\"\"Understanding how each algorithm is performing on the dataset\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                            \"\"\"Using Naive Bayes\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_nb = MultinomialNB(alpha = 1.0)\n",
    "clf_nb = model_nb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9564885496183206\n"
     ]
    }
   ],
   "source": [
    "prediction_nb =  clf_nb.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_nb))\n",
    "\n",
    "#the accuracy for naive bayes is quite good and even the predictions made are quite accurate when hashtags are given as the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports']\n",
      "['Politics']\n",
      "['Politics']\n",
      "['Politics']\n",
      "['Sports']\n",
      "['Politics']\n"
     ]
    }
   ],
   "source": [
    "print(clf_nb.predict(count_vect.transform([\"#indvaus\"])))\n",
    "print(clf_nb.predict(count_vect.transform([\"#EU\"])))\n",
    "print(clf_nb.predict(count_vect.transform([\"#white house\"])))\n",
    "print(clf_nb.predict(count_vect.transform([\"#MAKEAMERICAGREATAGAIN!\"])))\n",
    "print(clf_nb.predict(count_vect.transform([\"#rafalnadal\"])))\n",
    "print(clf_nb.predict(count_vect.transform([\"#trump2016\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                \"\"\"Using SVM\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model_svm = svm.LinearSVC()\n",
    "clf_svm = model_svm.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916793893129771\n"
     ]
    }
   ],
   "source": [
    "prediction_svm = clf_svm.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_svm))\n",
    "\n",
    "#the accuracy is lesser than Naive bayes, even the prediction for one hashtag is not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports']\n",
      "['Politics']\n",
      "['Sports']\n"
     ]
    }
   ],
   "source": [
    "print(clf_svm.predict(count_vect.transform([\"#indvaus\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"#trump2016\"])))\n",
    "print(clf_svm.predict(count_vect.transform([\"#MAKEAMERICAGREATAGAIN!\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                            \"\"\"Random Forest\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "model_rc=RandomForestClassifier(n_estimators=100, random_state = 42)\n",
    "model_rc.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9045801526717557\n"
     ]
    }
   ],
   "source": [
    "prediction_rc = model_rc.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_rc))\n",
    "\n",
    "#accuracy is much lesser and the predictions are not right for the poiltical tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports']\n",
      "['Sports']\n",
      "['Sports']\n",
      "['Sports']\n"
     ]
    }
   ],
   "source": [
    "print(model_rc.predict(count_vect.transform([\"#usopen\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"#MAKEAMERICAGREATAGAIN!\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"#trump2016\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"#tennis\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                                        \"\"\"KNeighbours classifier\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knn = KNeighborsClassifier()\n",
    "clf_knn.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9129770992366413\n"
     ]
    }
   ],
   "source": [
    "prediction_knn = clf_knn.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_knn))\n",
    "\n",
    "#accuracy not as good and even predictions are not great for political tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports']\n",
      "['Sports']\n",
      "['Sports']\n"
     ]
    }
   ],
   "source": [
    "print(clf_knn.predict(count_vect.transform([\"#ausopen\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"#MAKE AMERICA GREAT AGAIN!\"])))\n",
    "print(model_rc.predict(count_vect.transform([\"#trump2016\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                            \"\"\"Decision Tree\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model_dt=tree.DecisionTreeClassifier()\n",
    "model_dt.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7816793893129771\n"
     ]
    }
   ],
   "source": [
    "prediction_dt = model_dt.predict(count_vect.transform(X_test))\n",
    "print(accuracy_score(y_test, prediction_dt))\n",
    "\n",
    "#very low accuracy, and the predictions are also pretty off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports']\n",
      "['Sports']\n",
      "['Sports']\n"
     ]
    }
   ],
   "source": [
    "print(model_dt.predict(count_vect.transform([\"#ausopen\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"#Hillary\"])))\n",
    "print(model_dt.predict(count_vect.transform([\"#trump2016\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"From the above experiment, it is clear that Naive Bayes with close to 96 % accuracy is working best to \n",
    "classify a particular hashtag into a category on which the tweets have been trained.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                    \"\"\"Unsupervised Learning Approach\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is an attempt to understand the tweet categories in the dataset with the help of a topic modeling\n",
    "technique called Latent Dirichlet Allocation(LDA).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.corpora import Dictionary, bleicorpus\n",
    "import numpy\n",
    "from gensim.matutils import hellinger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##getting the data used above, but without the 'sports' and 'politics' labels\n",
    "docs = []\n",
    "store = \"\"\n",
    "file = open(\"/Users/Moukthika/Desktop/wkc/twitter_ldc.csv\", 'r', encoding = 'latin1')\n",
    "reader = csv.reader(file)\n",
    "for row in reader:\n",
    "    for i in row:\n",
    "        docs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the data\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(d):\n",
    "    stop_free = \" \".join([i for i in d.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(word for word in punc_free.split() if len(word)>4)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_clean = [clean(d).split() for d in docs]\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean] #generating a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using LDA algorithm from Gensim\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training our lda model\n",
    "\"\"\"although we know that there are two major topics in the data, the num_topics is initiated to 5 to understand how the algorithm \n",
    "extracts the topics from the dataset\"\"\"\n",
    "\n",
    "lda_model = Lda(doc_term_matrix, num_topics=5, id2word = dictionary, passes=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.014*\"video\" + 0.014*\"conference\" + 0.013*\"press\"'), (1, '0.022*\"president\" + 0.017*\"obama\" + 0.011*\"u2019s\"'), (2, '0.014*\"bbl02\" + 0.012*\"bigfinals\" + 0.008*\"gbfedcup\"'), (3, '0.026*\"indvaus\" + 0.016*\"fvnl1ktpb1\" + 0.012*\"india\"'), (4, '0.012*\"thanks\" + 0.008*\"medvedev\" + 0.006*\"great\"')]\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.print_topics(num_topics=5, num_words=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        \"\"\"Understanding the output\"\"\"\n",
    "\n",
    "#the first topic contains the words  video, conference and press and could all under either categories\n",
    "#the second topic is polotics as it has returned the words obama, president, 2019\n",
    "#The third is sports with the words gbfedcup, a hashtag and bigfinals \n",
    "#fourth is sports with words indvsaus, a hashtag and india\n",
    "#and fifth is politics too. \n",
    "\n",
    "#So clearly there are two major topics\n",
    "#let us try with num_topics = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = Lda(doc_term_matrix, num_topics=2, id2word = dictionary, passes=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.009*\"president\" + 0.005*\"video\" + 0.005*\"u2019s\"'), (1, '0.011*\"indvaus\" + 0.007*\"fvnl1ktpb1\" + 0.006*\"bbl02\"')]\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.print_topics(num_topics=2, num_words=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the two topics are thus politics and sports\n",
    "#however we will not be able to categorize a particular hastag into one of the two categories, we can still certainly classify \n",
    "#the topics and possibly get the distances of the hastags with one of the above topics identified. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
